import asyncio
import os
import json
from typing import List, Dict, Any
from openai import OpenAI
from dotenv import load_dotenv
from contextlib import AsyncExitStack
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
import gradio as gr

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

class MCPGradioClient:
    def __init__(self):
        """åˆå§‹åŒ–é›†æˆå®¢æˆ·ç«¯"""
        self.exit_stack = AsyncExitStack()
        self.api_key = os.getenv("ARK_API_KEY")  # è¯»å– OpenAI API Key
        self.base_url = os.getenv("ARK_BASE_URL")  # è¯»å– BASE URL
        self.model = os.getenv("ARK_MODEL")  # è¯»å– model
        
        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ° API KEY. è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® OPENAI_API_KEY")

        self.openai_client = OpenAI(api_key=self.api_key, base_url=self.base_url)
        self.sessions: Dict[str, Dict] = {}  # å­˜å‚¨å¤šä¸ªæœåŠ¡ç«¯ä¼šè¯
        self.tools_map: Dict[str, str] = {}  # å·¥å…·æ˜ å°„ï¼šå·¥å…·åç§° -> æœåŠ¡ç«¯ ID
        self.conversation_history: List[Dict[str, Any]] = []
        self.current_query = ""
        self.lock = asyncio.Lock()

    async def connect_to_server(self, server_id: str, server_script_path: str):
        """è¿æ¥åˆ° MCP æœåŠ¡å™¨"""
        if server_id in self.sessions:
            raise ValueError(f"æœåŠ¡ç«¯ {server_id} å·²ç»è¿æ¥")

        is_python = server_script_path.endswith('.py')
        is_js = server_script_path.endswith('.js')
        if not (is_python or is_js):
            raise ValueError("æœåŠ¡å™¨è„šæœ¬å¿…é¡»æ˜¯ Python æˆ– JavaScript æ–‡ä»¶")

        command = "python" if is_python else "node"
        server_params = StdioServerParameters(
            command=command,
            args=[server_script_path],
            env=None
        )

        # å¯åŠ¨ MCP æœåŠ¡å™¨å¹¶å»ºç«‹é€šä¿¡
        stdio_transport = await self.exit_stack.enter_async_context(
            stdio_client(server_params))
        stdio, write = stdio_transport
        session = await self.exit_stack.enter_async_context(
            ClientSession(stdio, write))

        await session.initialize()
        self.sessions[server_id] = {"session": session, "stdio": stdio, "write": write}
        print(f"å·²è¿æ¥åˆ° MCP æœåŠ¡å™¨: {server_id}")

        # æ›´æ–°å·¥å…·æ˜ å°„
        response = await session.list_tools()
        for tool in response.tools:
            self.tools_map[tool.name] = server_id

    async def process_query(self, query: str, temperature, max_length) -> str:
        """å¤„ç†ç”¨æˆ·æŸ¥è¯¢å¹¶è¿”å›å“åº”"""
        async with self.lock:
            self.current_query = query
            messages = self.conversation_history.copy()
            messages.append({"role": "user", "content": query})

            # æ„å»ºå·¥å…·åˆ—è¡¨
            available_tools = []
            for tool_name, server_id in self.tools_map.items():
                session = self.sessions[server_id]["session"]
                response = await session.list_tools()
                for tool in response.tools:
                    if tool.name == tool_name:
                        available_tools.append({
                            "type": "function",
                            "function": {
                                "name": tool.name,
                                "description": tool.description,
                                "input_schema": tool.inputSchema
                            }
                        })

            # å¾ªç¯å¤„ç†å·¥å…·è°ƒç”¨
            while True:
                response = self.openai_client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens= max_length,
                    tools=available_tools
                )

                choice = response.choices[0]
                message = choice.message
                
                # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
                assistant_msg = {
                    "role": "assistant",
                    "content": message.content
                }
                
                if message.tool_calls:
                    assistant_msg["tool_calls"] = [
                        {
                            "id": call.id,
                            "type": call.type,
                            "function": {
                                "name": call.function.name,
                                "arguments": call.function.arguments,
                            }
                        } for call in message.tool_calls
                    ]
                
                messages.append(assistant_msg)

                # å¤„ç†å·¥å…·è°ƒç”¨
                if choice.finish_reason == "tool_calls":
                    for tool_call in message.tool_calls:
                        tool_name = tool_call.function.name
                        tool_args = json.loads(tool_call.function.arguments)

                        server_id = self.tools_map.get(tool_name)
                        if not server_id:
                            raise ValueError(f"æœªæ‰¾åˆ°å·¥å…· {tool_name} å¯¹åº”çš„æœåŠ¡ç«¯")

                        session = self.sessions[server_id]["session"]
                        result = await session.call_tool(tool_name, tool_args)
                        
                        messages.append({
                            "role": "tool",
                            "content": result.content[0].text,
                            "tool_call_id": tool_call.id,
                        })
                
                if not choice.finish_reason == "tool_calls":
                    # æ›´æ–°å¯¹è¯å†å²ï¼ˆä¸å«å·¥å…·è°ƒç”¨ä¸­é—´æ­¥éª¤ï¼‰
                    self.conversation_history.extend([
                        {"role": "user", "content": query},
                        {"role": "assistant", "content": message.content}
                    ])
                    self._trim_history(max_length=10)
                    return message.content

    def _trim_history(self, max_length: int):
        """ä¿®å‰ªå†å²è®°å½•"""
        if len(self.conversation_history) > max_length * 2:
            self.conversation_history = self.conversation_history[-max_length * 2:]

    def get_conversation_html(self) -> str:
        """å°†å¯¹è¯å†å²æ ¼å¼åŒ–ä¸ºHTML"""
        html = "<div style='font-family: Arial, sans-serif; max-width: 800px; margin: auto;'>"
        for msg in self.conversation_history:
            if msg["role"] == "user":
                html += f"""
                <div style='margin-bottom: 10px;'>
                    <div style='background-color: #f0f7ff; padding: 10px; border-radius: 5px;'>
                        <strong>User:</strong> {msg['content']}
                    </div>
                </div>
                """
            elif msg["role"] == "assistant":
                html += f"""
                <div style='margin-bottom: 20px;'>
                    <div style='background-color: #e8f5e9; padding: 10px; border-radius: 5px;'>
                        <strong>Assistant:</strong> {msg['content']}
                    </div>
                </div>
                """
        html += "</div>"
        return html

    async def clean(self):
        """æ¸…ç†æ‰€æœ‰èµ„æº"""
        await self.exit_stack.aclose()
        self.sessions.clear()
        self.tools_map.clear()
        self.conversation_history.clear()

async def setup_mcp_client():
    """åˆå§‹åŒ–MCPå®¢æˆ·ç«¯å¹¶è¿æ¥æœåŠ¡å™¨"""
    client = MCPGradioClient()
    
    try:
        # åŠ è½½é…ç½®æ–‡ä»¶
        config_path = 'registry.json'
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨")
        
        with open(config_path, 'r') as f:
            config = json.load(f)
        
        # è¿æ¥åˆ°æ‰€æœ‰é…ç½®çš„æœåŠ¡å™¨
        for server in config.get("servers", []):
            name = server.get("name")
            script = server.get("script")
            
            if name and script:
                abs_script = os.path.abspath(script)
                if os.path.exists(abs_script):
                    try:
                        await client.connect_to_server(name, abs_script)
                    except Exception as e:
                        print(f"è¿æ¥æœåŠ¡å™¨ {name} å¤±è´¥: {str(e)}")
        
        return client
    
    except Exception as e:
        print(f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        await client.clean()
        raise

async def gradio_respond(query: str, client: MCPGradioClient, temperature: float = 0.7, max_length: int = 500):
    """å¤„ç†Gradioç•Œé¢æäº¤çš„æŸ¥è¯¢"""
    if not query.strip():
        return "", client.get_conversation_html()
    
    try:
        response = await client.process_query(query, temperature, max_length)
        return "", client.get_conversation_html()
    except Exception as e:
        error_msg = f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}"
        client.conversation_history.append(
            {"role": "user", "content": query}
        )
        client.conversation_history.append(
            {"role": "assistant", "content": error_msg}
        )
        return "", client.get_conversation_html()

def create_gradio_interface(client: MCPGradioClient):
    """åˆ›å»ºGradioç•Œé¢"""
    with gr.Blocks(title="CTAgent", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ› ï¸ CTAgent")
        gr.Markdown("CTAgent created by CASIA & Tsinghua University")
        
        with gr.Row():
            with gr.Column(scale=3):
                # å¯¹è¯å†å²æ˜¾ç¤º
                chat_display = gr.HTML(client.get_conversation_html())
                
                # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
                with gr.Row():
                    user_input = gr.Textbox(
                        placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æŒ‡ä»¤...",
                        label="ç”¨æˆ·è¾“å…¥",
                        scale=4,
                        container=False
                    )
                    submit_btn = gr.Button("å‘é€", variant="primary")
                
                # æ§åˆ¶é¢æ¿
                with gr.Accordion("é«˜çº§é€‰é¡¹", open=False):
                    temperature = gr.Slider(
                        minimum=0,
                        maximum=1,
                        value=0.7,
                        step=0.1,
                        label="æ¸©åº¦ (æ§åˆ¶éšæœºæ€§)"
                    )
                    max_length = gr.Slider(
                        minimum=100,
                        maximum=1000,
                        value=500,
                        step=50,
                        label="æœ€å¤§ç”Ÿæˆé•¿åº¦"
                    )
                clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯å†å²", variant="stop")
            
            # å³ä¾§ä¿¡æ¯æ 
            with gr.Column(scale=1):
                gr.Markdown("### å·²è¿æ¥å·¥å…·")
                tools_info = gr.JSON(
                    value={"å·²è¿æ¥å·¥å…·": list(client.tools_map.keys())},
                    label="å·¥å…·åˆ—è¡¨"
                )
                
                gr.Markdown("### ä½¿ç”¨è¯´æ˜")
                gr.Markdown("- è¾“å…¥é—®é¢˜åç‚¹å‡»å‘é€æˆ–æŒ‰Enter")
                gr.Markdown("- MCPä¼šè‡ªåŠ¨è°ƒç”¨åˆé€‚çš„å·¥å…·")
                gr.Markdown("- æ¸…ç©ºå†å²ä¸ä¼šæ–­å¼€æœåŠ¡å™¨è¿æ¥")
        
        # äº‹ä»¶ç»‘å®š
        submit_btn.click(
            fn=lambda q, temperature, max_length: gradio_respond(q, client, temperature, max_length),
            inputs=[user_input, temperature, max_length],
            outputs=[user_input, chat_display]
        )
        
        user_input.submit(
            fn=lambda q, temperature, max_length: gradio_respond(q, client, temperature, max_length),
            inputs=[user_input, temperature, max_length],
            outputs=[user_input, chat_display]
        )
        
        clear_btn.click(
            fn=lambda: (client.conversation_history.clear(), client.get_conversation_html()),
            inputs=[],
            outputs=[chat_display]
        )
    
    return demo

async def main():
    # åˆå§‹åŒ–MCPå®¢æˆ·ç«¯
    client = await setup_mcp_client()
    
    # åˆ›å»ºGradioç•Œé¢
    demo = create_gradio_interface(client)
    
    # å¯åŠ¨åº”ç”¨
    demo.launch(server_name="127.0.0.1", server_port=7860)

if __name__ == "__main__":
    asyncio.run(main())