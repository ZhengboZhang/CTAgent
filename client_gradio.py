import asyncio
import os
import json
from typing import List, Dict, Any
from functools import partial
from openai import OpenAI
from dotenv import load_dotenv
from contextlib import AsyncExitStack
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
import gradio as gr
import threading
from concurrent.futures import ThreadPoolExecutor
import queue

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class AsyncExecutor:
    """ä¸“é—¨å¤„ç†å¼‚æ­¥æ“ä½œçš„æ‰§è¡Œå™¨"""

    def __init__(self):
        self.loop = asyncio.new_event_loop()
        self.executor = ThreadPoolExecutor(max_workers=1)
        self.thread = None
        self.start()

    def start(self):
        """å¯åŠ¨å¼‚æ­¥çº¿ç¨‹"""

        def run_loop():
            asyncio.set_event_loop(self.loop)
            self.loop.run_forever()

        self.thread = threading.Thread(target=run_loop, daemon=True)
        self.thread.start()

    def run_async(self, coro):
        """åœ¨å¼‚æ­¥çº¿ç¨‹ä¸­è¿è¡Œåç¨‹"""
        if not self.loop.is_running():
            self.start()

        future = asyncio.run_coroutine_threadsafe(coro, self.loop)
        return future.result()

    def shutdown(self):
        """å…³é—­æ‰§è¡Œå™¨"""
        if self.loop.is_running():
            self.loop.call_soon_threadsafe(self.loop.stop)
        if self.thread and self.thread.is_alive():
            self.thread.join(timeout=1.0)
        self.executor.shutdown()


class MCPGradioClient:
    def __init__(self):
        """åˆå§‹åŒ–é›†æˆå®¢æˆ·ç«¯"""
        self.async_executor = AsyncExecutor()
        self.api_key = os.getenv("ARK_API_KEY")
        self.base_url = os.getenv("ARK_BASE_URL")
        self.model = os.getenv("ARK_MODEL")

        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ° API KEY. è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® OPENAI_API_KEY")

        self.openai_client = OpenAI(api_key=self.api_key, base_url=self.base_url)
        self.sessions: Dict[str, Dict] = {}
        self.tools_map: Dict[str, str] = {}
        self.conversation_history: List[Dict[str, Any]] = []
        self.current_query = ""
        self.uploaded_files = []
        self.exit_stack = AsyncExitStack()

    def connect_to_server(self, server_id: str, server_script_path: str):
        """åŒæ­¥æ–¹å¼è¿æ¥åˆ° MCP æœåŠ¡å™¨"""
        return self.async_executor.run_async(self._connect_to_server_async(server_id, server_script_path))

    async def _connect_to_server_async(self, server_id: str, server_script_path: str):
        """å¼‚æ­¥è¿æ¥æœåŠ¡å™¨"""
        if server_id in self.sessions:
            raise ValueError(f"æœåŠ¡ç«¯ {server_id} å·²ç»è¿æ¥")

        is_python = server_script_path.endswith('.py')
        is_js = server_script_path.endswith('.js')
        if not (is_python or is_js):
            raise ValueError("æœåŠ¡å™¨è„šæœ¬å¿…é¡»æ˜¯ Python æˆ– JavaScript æ–‡ä»¶")

        command = "python" if is_python else "node"
        server_params = StdioServerParameters(
            command=command,
            args=[server_script_path],
            env=None
        )

        # å¯åŠ¨ MCP æœåŠ¡å™¨å¹¶å»ºç«‹é€šä¿¡
        stdio_transport = await self.exit_stack.enter_async_context(
            stdio_client(server_params))
        stdio, write = stdio_transport
        session = await self.exit_stack.enter_async_context(
            ClientSession(stdio, write))

        await session.initialize()
        self.sessions[server_id] = {"session": session, "stdio": stdio, "write": write}
        print(f"å·²è¿æ¥åˆ° MCP æœåŠ¡å™¨: {server_id}")

        # æ›´æ–°å·¥å…·æ˜ å°„
        response = await session.list_tools()
        for tool in response.tools:
            self.tools_map[tool.name] = server_id

    def process_uploaded_files(self, files):
        """åŒæ­¥æ–¹å¼å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
        return self.async_executor.run_async(self._process_uploaded_files_async(files))

    async def _process_uploaded_files_async(self, files):
        """å¼‚æ­¥å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶"""
        file_info = []
        for file in files:
            file_path = file.name
            file_name = os.path.basename(file_path)
            file_size = os.path.getsize(file_path)
            file_type = file_name.split('.')[-1].lower()

            info = {
                "æ–‡ä»¶å": file_name,
                "æ–‡ä»¶ç±»å‹": file_type,
                "æ–‡ä»¶å¤§å°": f"{file_size} å­—èŠ‚",
                "æ–‡ä»¶è·¯å¾„": file_path
            }

            # æ·»åŠ åˆ°ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨
            self.uploaded_files.append(info)
            file_info.append(info)

        return file_info

    def process_query(self, query: str, temperature: float, max_length: int) -> str:
        """åŒæ­¥æ–¹å¼å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        return self.async_executor.run_async(self._process_query_async(query, temperature, max_length))

    async def _process_query_async(self, query: str, temperature: float, max_length: int) -> str:
        """å¼‚æ­¥å¤„ç†ç”¨æˆ·æŸ¥è¯¢"""
        self.current_query = query

        # æ·»åŠ ä¸Šä¼ æ–‡ä»¶ä¿¡æ¯åˆ°æŸ¥è¯¢ä¸­
        if self.uploaded_files:
            file_info = "\n".join([f"{f['æ–‡ä»¶è·¯å¾„']}" for f in self.uploaded_files])
            enhanced_query = f"è¯·è¯»å–æ–‡ä»¶ï¼š'{file_info}'ï¼Œæå–å…¶ä¸­çš„å›¾ç‰‡å’Œæ–‡å­—ï¼Œå¹¶å®ç°ä»¥ä¸‹æŒ‡ä»¤ï¼š\n{query}"
        else:
            enhanced_query = query

        print(enhanced_query)

        messages = self.conversation_history.copy()
        messages.append({"role": "user", "content": enhanced_query})

        # ä½¿ç”¨é¢„åŠ è½½çš„å·¥å…·åˆ—è¡¨
        available_tools = self.available_tools

        # å¾ªç¯å¤„ç†å·¥å…·è°ƒç”¨
        while True:
            response = self.openai_client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_length,
                tools=available_tools
            )

            print(response)

            choice = response.choices[0]
            message = choice.message

            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯åˆ°å†å²
            assistant_msg = {
                "role": "assistant",
                "content": message.content
            }

            if message.tool_calls:
                assistant_msg["tool_calls"] = [
                    {
                        "id": call.id,
                        "type": call.type,
                        "function": {
                            "name": call.function.name,
                            "arguments": call.function.arguments,
                        }
                    } for call in message.tool_calls
                ]

            print(message)
            messages.append(assistant_msg)

            # å¤„ç†å·¥å…·è°ƒç”¨
            if choice.finish_reason == "tool_calls":
                for tool_call in message.tool_calls:
                    tool_name = tool_call.function.name
                    tool_args = json.loads(tool_call.function.arguments)

                    server_id = self.tools_map.get(tool_name)
                    if not server_id:
                        raise ValueError(f"æœªæ‰¾åˆ°å·¥å…· {tool_name} å¯¹åº”çš„æœåŠ¡ç«¯")

                    session = self.sessions[server_id]["session"]
                    result = await session.call_tool(tool_name, tool_args)
                    print(f"\n\n[Calling tool {tool_name} on server {server_id} with args {tool_args}]\n\n")

                    messages.append({
                        "role": "tool",
                        "content": result.content[0].text,
                        "tool_call_id": tool_call.id,
                    })

            if not choice.finish_reason == "tool_calls":
                # æ›´æ–°å¯¹è¯å†å²ï¼ˆä¸å«å·¥å…·è°ƒç”¨ä¸­é—´æ­¥éª¤ï¼‰
                self.conversation_history.extend([
                    {"role": "user", "content": enhanced_query},
                    {"role": "assistant", "content": message.content}
                ])
                self._trim_history(max_length=10)
                return message.content

    def list_tools(self):
        """åŒæ­¥æ–¹å¼åˆ—å‡ºå·¥å…·"""
        self.async_executor.run_async(self._list_tools_async())

    async def _list_tools_async(self):
        """å¼‚æ­¥åˆ—å‡ºå·¥å…·"""
        if not self.sessions:
            print("æ²¡æœ‰å·²è¿æ¥çš„æœåŠ¡ç«¯")
            return

        print("å·²è¿æ¥çš„æœåŠ¡ç«¯å·¥å…·åˆ—è¡¨:")
        for tool_name, server_id in self.tools_map.items():
            print(f"å·¥å…·: {tool_name}, æ¥æºæœåŠ¡ç«¯: {server_id}")

    def _trim_history(self, max_length: int):
        """ä¿®å‰ªå†å²è®°å½•"""
        if len(self.conversation_history) > max_length * 2:
            self.conversation_history = self.conversation_history[-max_length * 2:]

    def get_conversation_html(self) -> str:
        """å°†å¯¹è¯å†å²æ ¼å¼åŒ–ä¸ºHTML"""
        html = "<div style='font-family: Arial, sans-serif; max-width: 800px; margin: auto;'>"
        for msg in self.conversation_history:
            content = msg['content'].replace('\n', '<br>')
            if msg["role"] == "user":
                html += f"""
                <div style='margin-bottom: 10px;'>
                    <div style='background-color: #f0f7ff; padding: 10px; border-radius: 5px;'>
                        <strong>User:</strong> {content}
                    </div>
                </div>
                """
            elif msg["role"] == "assistant":
                html += f"""
                <div style='margin-bottom: 20px;'>
                    <div style='background-color: #e8f5e9; padding: 10px; border-radius: 5px;'>
                        <strong>Assistant:</strong> {content}
                    </div>
                </div>
                """
        html += "</div>"
        return html

    def get_file_preview_html(self) -> str:
        """è·å–æ–‡ä»¶é¢„è§ˆçš„HTML"""
        if not self.uploaded_files:
            return "<div style='color: #666; font-style: italic;'>æš‚æ— ä¸Šä¼ æ–‡ä»¶</div>"

        html = "<div style='font-family: Arial, sans-serif;'>"
        html += "<h4>ğŸ“ å·²ä¸Šä¼ æ–‡ä»¶:</h4>"
        for file in self.uploaded_files:
            html += f"""
            <div style='background-color: #f5f5f5; padding: 8px; margin: 5px 0; border-radius: 4px;'>
                ğŸ“„ {file['æ–‡ä»¶å']} <span style='color: #666; font-size: 0.9em;'>({file['æ–‡ä»¶ç±»å‹']}, {file['æ–‡ä»¶å¤§å°']})</span>
            </div>
            """
        html += "</div>"
        return html

    def clean(self):
        """æ¸…ç†æ‰€æœ‰èµ„æº"""
        self.async_executor.run_async(self._clean_async())
        self.async_executor.shutdown()

    async def _clean_async(self):
        """å¼‚æ­¥æ¸…ç†èµ„æº"""
        await self.exit_stack.aclose()
        self.sessions.clear()
        self.tools_map.clear()
        self.conversation_history.clear()
        self.uploaded_files.clear()


def setup_mcp_client():
    """åˆå§‹åŒ–MCPå®¢æˆ·ç«¯å¹¶è¿æ¥æœåŠ¡å™¨"""
    client = MCPGradioClient()

    try:
        # åŠ è½½é…ç½®æ–‡ä»¶
        config_path = 'registry.json'
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨")

        with open(config_path, 'r') as f:
            config = json.load(f)

        # è¿æ¥åˆ°æ‰€æœ‰é…ç½®çš„æœåŠ¡å™¨
        for server in config.get("servers", []):
            name = server.get("name")
            script = server.get("script")

            if name and script:
                abs_script = os.path.abspath(script)
                if os.path.exists(abs_script):
                    try:
                        client.connect_to_server(name, abs_script)
                    except Exception as e:
                        print(f"è¿æ¥æœåŠ¡å™¨ {name} å¤±è´¥: {str(e)}")

        # é¢„åŠ è½½æ‰€æœ‰å·¥å…·ä¿¡æ¯
        client.available_tools = []
        for tool_name, server_id in client.tools_map.items():
            # è¿™é‡Œéœ€è¦åŒæ­¥è·å–å·¥å…·ä¿¡æ¯
            session_info = client.sessions[server_id]
            response = client.async_executor.run_async(session_info["session"].list_tools())
            for tool in response.tools:
                if tool.name == tool_name:
                    client.available_tools.append({
                        "type": "function",
                        "function": {
                            "name": tool.name,
                            "description": tool.description,
                            "input_schema": tool.inputSchema
                        }
                    })

        print(f"é¢„åŠ è½½ {len(client.available_tools)} ä¸ªå·¥å…·")
        return client

    except Exception as e:
        print(f"åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        client.clean()
        raise


def gradio_respond(query: str, temperature: float, max_length: int, client: MCPGradioClient):
    """å¤„ç†Gradioç•Œé¢æäº¤çš„æŸ¥è¯¢"""
    if not query.strip():
        return "", client.get_conversation_html(), client.get_file_preview_html()

    try:
        response = client.process_query(query, temperature, max_length)
        return "", client.get_conversation_html(), client.get_file_preview_html()
    except Exception as e:
        error_msg = f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}"
        client.conversation_history.append({"role": "user", "content": query})
        client.conversation_history.append({"role": "assistant", "content": error_msg})
        return "", client.get_conversation_html(), client.get_file_preview_html()


def gradio_upload_files(files, client: MCPGradioClient):
    """å¤„ç†æ–‡ä»¶ä¸Šä¼ """
    if files:
        file_info = client.process_uploaded_files(files)
        return client.get_file_preview_html()
    return client.get_file_preview_html()


def create_gradio_interface(client):
    """åˆ›å»ºGradioç•Œé¢"""
    with gr.Blocks(title="CTAgent", theme=gr.themes.Soft()) as demo:
        gr.Markdown("# ğŸ› ï¸ CTAgent with File Upload")
        gr.Markdown("CTAgent created by CASIA & Tsinghua University - æ”¯æŒæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½")

        respond_with_client = partial(gradio_respond, client=client)
        upload_with_client = partial(gradio_upload_files, client=client)

        # ç•Œé¢ä»£ç ä¿æŒä¸å˜...
        with gr.Row():
            with gr.Column(scale=3):
                with gr.Row():
                    file_upload = gr.File(
                        file_count="multiple",
                        label="ä¸Šä¼ æ–‡ä»¶",
                        file_types=[
                            ".jpg", ".jpeg", ".png", ".gif", ".bmp",
                            ".pdf", ".txt", ".docx", ".csv", ".json"
                        ]
                    )

                file_preview = gr.HTML(client.get_file_preview_html())
                chat_display = gr.HTML(client.get_conversation_html())

                with gr.Row():
                    user_input = gr.Textbox(
                        placeholder="è¾“å…¥æ‚¨çš„é—®é¢˜æˆ–æŒ‡ä»¤...",
                        label="ç”¨æˆ·è¾“å…¥",
                        scale=4,
                        container=False
                    )
                    submit_btn = gr.Button("å‘é€", variant="primary")

                with gr.Accordion("é«˜çº§é€‰é¡¹", open=False):
                    temperature = gr.Slider(
                        minimum=0, maximum=1, value=0.7, step=0.1, label="æ¸©åº¦ (æ§åˆ¶éšæœºæ€§)"
                    )
                    max_length = gr.Slider(
                        minimum=100, maximum=10000, value=2000, step=50, label="æœ€å¤§ç”Ÿæˆé•¿åº¦"
                    )

                with gr.Row():
                    clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯å†å²", variant="stop")
                    clear_files_btn = gr.Button("æ¸…ç©ºä¸Šä¼ æ–‡ä»¶", variant="secondary")

            with gr.Column(scale=1):
                gr.Markdown("### å·²è¿æ¥å·¥å…·")
                tools_info = gr.JSON(
                    value={"å·²è¿æ¥å·¥å…·": list(client.tools_map.keys())},
                    label="å·¥å…·åˆ—è¡¨"
                )

                gr.Markdown("### ä½¿ç”¨è¯´æ˜")
                gr.Markdown("- æ”¯æŒä¸Šä¼ å›¾ç‰‡ã€PDFã€æ–‡æ¡£ã€CSVç­‰æ–‡ä»¶")
                gr.Markdown("- ä¸Šä¼ æ–‡ä»¶åå¯ä»¥åœ¨å¯¹è¯ä¸­å¼•ç”¨æ–‡ä»¶å†…å®¹")
                gr.Markdown("- MCPä¼šè‡ªåŠ¨è°ƒç”¨åˆé€‚çš„å·¥å…·å¤„ç†æ–‡ä»¶")
                gr.Markdown("- æ¸…ç©ºå†å²ä¸ä¼šæ–­å¼€æœåŠ¡å™¨è¿æ¥")

        # äº‹ä»¶ç»‘å®š
        submit_btn.click(
            fn=respond_with_client,
            inputs=[user_input, temperature, max_length],
            outputs=[user_input, chat_display, file_preview]
        )

        user_input.submit(
            fn=respond_with_client,
            inputs=[user_input, temperature, max_length],
            outputs=[user_input, chat_display, file_preview]
        )

        file_upload.upload(
            fn=upload_with_client,
            inputs=[file_upload],
            outputs=[file_preview]
        )

        clear_btn.click(
            fn=lambda: (
            client.conversation_history.clear(), client.get_conversation_html(), client.get_file_preview_html()),
            inputs=[],
            outputs=[chat_display, file_preview]
        )

        clear_files_btn.click(
            fn=lambda: (client.uploaded_files.clear(), client.get_file_preview_html()),
            inputs=[],
            outputs=[file_preview]
        )

    return demo


def main():
    # åˆå§‹åŒ–MCPå®¢æˆ·ç«¯
    client = setup_mcp_client()
    client.list_tools()

    # åˆ›å»ºGradioç•Œé¢
    demo = create_gradio_interface(client)

    # å¯åŠ¨åº”ç”¨
    demo.launch(server_name="127.0.0.1", server_port=7861)

    # ç¨‹åºé€€å‡ºæ—¶æ¸…ç†èµ„æº
    client.clean()


if __name__ == "__main__":
    main()